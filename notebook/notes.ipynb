{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Mewari's\\Desktop\\New folder\\Nlp Project\\venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Mewari's\\Desktop\\New folder\\Nlp Project\\venv\\lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\",model=\"Falconsai/text_summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 1000, but your input_length is only 75. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=37)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'It is here you must be careful not to focus too much on the details, but only write down what is of essential importance to the story . There is no need to be too detailed since it is not the point .'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "After you have read the piece, you can jot down the main points. It is here you must be careful not to focus too much on the details, but only write down what is of essential importance to the story, i.e. only the major plots. There is no need to be too detailed since it is not the point.\n",
    "\"\"\"\n",
    "\n",
    "summarize_text = summarizer(text, max_length=1000, min_length=30, do_sample=True)\n",
    "summarize_text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is here you must be careful not to focus too much on the details, but only write down what is of essential importance to the story . There is no need to be too detailed since it is not the point .'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_text[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected Sentence: bravery id help to get that\n",
      "Exceptions List: ['Breavery', 'Hellp']\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "# Initialize spell checker\n",
    "spell = SpellChecker()\n",
    "\n",
    "# Function to correct spelling in a sentence\n",
    "def correct_sentence(sentence, exceptions=None):\n",
    "    # Initialize exceptions list if not provided\n",
    "    exceptions = exceptions or []\n",
    "    \n",
    "    # Add unknown words to exceptions\n",
    "    exceptions += [word for word in sentence.split() if word not in spell]\n",
    "\n",
    "    # Correct spelling while ignoring exceptions\n",
    "    corrected_words = [spell.correction(word.lower()) if word.lower() not in exceptions else word for word in sentence.split()]\n",
    "    \n",
    "    corrected_sentence = ' '.join(corrected_words)\n",
    "    return corrected_sentence, exceptions\n",
    "\n",
    "# Example usage\n",
    "sentence = \"Breavery Id Hellp to get that\"\n",
    "corrected_sentence, exceptions = correct_sentence(sentence)\n",
    "\n",
    "print(\"Corrected Sentence:\", corrected_sentence)\n",
    "print(\"Exceptions List:\", exceptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
